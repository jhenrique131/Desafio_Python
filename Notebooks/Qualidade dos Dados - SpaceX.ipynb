{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8b12433-8df7-4351-b31a-eb2d907f4de7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Qualidade de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf9139c1-0bf0-476d-98ae-4680a726267b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Observação:\n",
    "Os arquvivoos estão sendo salvos em formato Delta, devido a importancia da garantia da eficiência e confiabilidade dos dados. Dessa forma, temos consultas melhoradas e alterações seguras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35bd57f1-7ed7-476f-908e-dde5409244a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importa funções do PySpark para manipulação de colunas e cálculos\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ====================================================\n",
    "# Função que gera relatório de qualidade de dados\n",
    "# ====================================================\n",
    "def data_quality_report(nome_tabela, fonte_dados, range_checks={}):\n",
    "    \"\"\"\n",
    "    Gera um relatório de qualidade de dados para uma tabela Spark.\n",
    "\n",
    "    Params:\n",
    "        nome_tabela (str): Nome da tabela no catálogo (ex: \"workspace.silver.pokemon\")\n",
    "        fonte_dados (str): Nome da fonte (ex: \"pokemon\", \"spacex\")\n",
    "        range_checks (dict): Dicionário de checagens de range, ex:\n",
    "                             {\"stages\": (1, 5), \"date_utc\": (\"2000-01-01\", \"2030-01-01\")}\n",
    "    \"\"\"\n",
    "\n",
    "    # Lê a tabela Delta no catálogo a partir do nome passado\n",
    "    df = spark.table(nome_tabela)\n",
    "\n",
    "    # Conta o número total de linhas na tabela\n",
    "    qtd_rows = df.count()\n",
    "\n",
    "    # Inicializa lista para armazenar os percentuais de valores nulos por coluna\n",
    "    null_ratios = []\n",
    "\n",
    "    # Loop sobre todas as colunas da tabela\n",
    "    for nome_coluna in df.columns:\n",
    "        # Conta quantos valores nulos existem na coluna atual\n",
    "        null_count = df.filter(F.col(nome_coluna).isNull()).count()\n",
    "\n",
    "        # Calcula o percentual de nulos (se houver linhas)\n",
    "        ratio = (null_count / qtd_rows) * 100 if qtd_rows > 0 else 0\n",
    "\n",
    "        # Adiciona o percentual à lista de ratios\n",
    "        null_ratios.append(ratio)\n",
    "\n",
    "    # Calcula a média dos percentuais de nulos entre todas as colunas\n",
    "    null_ratio_med = sum(null_ratios) / len(df.columns) if len(df.columns) > 0 else 0\n",
    "\n",
    "    # Dicionário que armazenará os resultados dos range checks\n",
    "    range_results = {}\n",
    "\n",
    "    # Loop pelos campos que têm regras de range definidas\n",
    "    for nome_coluna, (min_val, max_val) in range_checks.items():\n",
    "        # Só aplica se a coluna existir na tabela\n",
    "        if nome_coluna in df.columns:\n",
    "            # Se os valores mínimos/máximos forem numéricos\n",
    "            if isinstance(min_val, (int, float)):\n",
    "                invalid_count = df.filter(\n",
    "                    (F.col(nome_coluna) < min_val) | (F.col(nome_coluna) > max_val)\n",
    "                ).count()\n",
    "            # Se forem strings (datas ou formatos de texto)\n",
    "            else:\n",
    "                invalid_count = df.filter(\n",
    "                    (F.col(nome_coluna) < F.lit(min_val)) | (F.col(nome_coluna) > F.lit(max_val))\n",
    "                ).count()\n",
    "\n",
    "            # Armazena no dicionário quantos valores estão fora do range\n",
    "            range_results[nome_coluna] = invalid_count\n",
    "\n",
    "    # Cria a linha do relatório com os resultados consolidados\n",
    "    report = [(fonte_dados, qtd_rows, null_ratio_med, str(range_results))]\n",
    "\n",
    "    # Converte a linha para um DataFrame Spark com colunas fixas\n",
    "    report_df = spark.createDataFrame(\n",
    "        report, [\"FONTE_DADOS\", \"QTD_ROWS\", \"NULL_RATIO_MED\", \"RANGE_CHECKS\"]\n",
    "    )\n",
    "\n",
    "    # Retorna o relatório em formato DataFrame\n",
    "    return report_df\n",
    "\n",
    "# ====================================================\n",
    "# Executa relatório para a fonte Pokémon\n",
    "# ====================================================\n",
    "pokemon_report = data_quality_report(\n",
    "    nome_tabela=\"workspace.silver.pokemon\",   # Nome da tabela Silver com dados Pokémon\n",
    "    fonte_dados=\"pokemon\",                    # Nome da fonte\n",
    "    range_checks={\"url\": (\"https://pokeapi.co/api/v2/\", \"https://pokeapi.co/api/v2/zzzz\")}  \n",
    "    # Define um range \"fake\" só para verificar se o formato da URL está coerente\n",
    ")\n",
    "\n",
    "# ====================================================\n",
    "# Executa relatório para a fonte SpaceX\n",
    "# ====================================================\n",
    "spacex_report = data_quality_report(\n",
    "    nome_tabela=\"workspace.silver.spacex_launches\",  # Nome da tabela Silver com lançamentos\n",
    "    fonte_dados=\"spacex_launches\",                   # Nome da fonte\n",
    "    range_checks={\"stages\": (1, 5), \"date_utc\": (\"2000-01-01\", \"2030-01-01\")}  \n",
    "    # Checa se estágios estão entre 1 e 5 e se as datas estão dentro do range esperado\n",
    ")\n",
    "\n",
    "# ====================================================\n",
    "# Consolida relatórios em uma única tabela\n",
    "# ====================================================\n",
    "final_report = pokemon_report.union(spacex_report)  # Une os dois relatórios em um só DataFrame\n",
    "\n",
    "# Salva os resultados no catálogo (camada de qualidade)\n",
    "final_report.write.format(\"delta\").mode(\"append\").saveAsTable(\"workspace.quality.data_quality_report\")\n",
    "\n",
    "# Exibe os resultados finais no notebook\n",
    "display(final_report)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Qualidade dos Dados - SpaceX",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
